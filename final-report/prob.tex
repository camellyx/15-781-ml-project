\section{Background and Related Work}
\label{sec:problem}

In this section, we first introduce several common neural networks model,
Logistic Regression (single neuron) model, Multi-Layer Perceptron (MLP) model,
and Convolutional Neuron Networks (CoNet) model. Then we summarize several
related works that introduce noise into those models to improve accuracy.

\subsection{Neural Networks Background}

The simplest form of a neural network, which is also the primary component of
any neural network model, is a single neuron. Figure~\ref{fig:single-neuron}
illustrates a single-neuron neural network, which is also known as the Logistic
Regression (LR) model. The neuron shown in the figure consumes a vector of
numbers ($\{X_i\}$) as inputs, and produces a single number as its output. 




In this project, we will investigate the hypothesis that consistency
relaxing can improve model accuracy by introducing various types of noise
into different neural network models.

We compare our results with recent works in~\cite{chilimbi14adam,
wan2013dropconnect, goodfellow13maxout, dean2012large} and consider any
improvement in accuracy or convergence rate in the final results to be a
success.


